{% extends 'base.html' %}

{% block title %}Upload Media for SyncKing-Kong{% endblock %}

{% block content %}

<div class="upload-page">
    <div class="container">
        <div class="row">
            <div class="col-1"></div>
            <div class="col-10">
                <div class="upload-content">
                    <h1>Upload Video and Audio for SyncKing-Kong</h1>
                    <p>Please upload your video file below:</p>
                </div>
                <form method="POST" action="{{ url_for('upload_media') }}" enctype="multipart/form-data">
                    <div class="upload-section" style="padding-bottom: 20px;">
                        <h2>Upload Video</h2>
                        <input type="file" name="video" accept="video/mpeg,video/mp4" required>
                    </div>
                    <p>
                        Please note that you can use only one feature at a time: <strong>Upload</strong> or
                        <strong>Record</strong>.
                        To revert the last action, <em>reload the page</em>.
                    </p>
                    <div class="upload-section" style="padding-bottom: 20px;">
                        <h2>Upload or Record Audio</h2>
                        <input type="file" id="audio-upload" name="audio" accept="audio/mpeg, audio/mp3">
                        <p>OR</p>
                        <button type="button" id="start-recording" class="btn-primary">Record Audio</button>
                        <button type="button" id="stop-recording" class="btn-primary" disabled>Stop Recording</button>
                        <audio id="audio-preview" controls style="display: none; margin-top: 10px;"></audio>
                        <div id="recording-alert" style="display: none; margin-top: 10px; color: red;">
                            Voice recording has been started. Recording time: <span id="recording-time">0</span>
                            seconds.
                        </div>
                    </div>
                    <div>
                        <input type="submit" value="Upload" class="btn-primary" style="width: 25%;">
                    </div>
                </form>
            </div>
            <div class="col-1"></div>
        </div>
    </div>
</div>

<script>
let audioChunks = [];
let mediaRecorder = null;
let audioBlob = null;
let startTrim = 0; // Start time for trimming (in seconds)
let endTrim = 0;   // End time for trimming (in seconds)
let recordingTimer = null;
let secondsElapsed = 0;

// Elements
const startButton = document.getElementById("startButton");
const stopButton = document.getElementById("stopButton");
const audioPreview = document.getElementById("audioPreview");
const recordingAlert = document.getElementById("recordingAlert");
const recordingTime = document.getElementById("recordingTime");

// Start the recording timer
function startRecordingTimer() {
    recordingTimer = setInterval(() => {
        secondsElapsed++;
        recordingTime.textContent = secondsElapsed + " seconds";
    }, 1000);
}

// Stop the recording timer
function stopRecordingTimer() {
    clearInterval(recordingTimer);
    recordingTimer = null;
    secondsElapsed = 0;
}

// Function to trim audio
async function trimAudio(blob, startTime, endTime) {
    const audioContext = new AudioContext();
    const arrayBuffer = await blob.arrayBuffer();
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

    // Calculate the start and end in samples
    const sampleRate = audioBuffer.sampleRate;
    const startSample = Math.floor(startTime * sampleRate);
    const endSample = Math.floor(endTime * sampleRate);

    // Create a new audio buffer for the trimmed audio
    const trimmedBuffer = audioContext.createBuffer(
        audioBuffer.numberOfChannels,
        endSample - startSample,
        sampleRate
    );

    // Copy the trimmed samples to the new buffer
    for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
        const channelData = audioBuffer.getChannelData(channel);
        trimmedBuffer.copyToChannel(
            channelData.subarray(startSample, endSample),
            channel
        );
    }

    // Export the trimmed buffer to a Blob
    const trimmedBlob = await bufferToWaveBlob(trimmedBuffer);
    return trimmedBlob;
}

// Function to convert audio buffer to a Blob
async function bufferToWaveBlob(buffer) {
    const audioContext = new OfflineAudioContext(
        buffer.numberOfChannels,
        buffer.length,
        buffer.sampleRate
    );
    const source = audioContext.createBufferSource();
    source.buffer = buffer;
    source.connect(audioContext.destination);
    source.start();

    const renderedBuffer = await audioContext.startRendering();
    const waveBlob = await audioBufferToWaveBlob(renderedBuffer);
    return waveBlob;
}

// Convert an audio buffer to a WAV Blob
function audioBufferToWaveBlob(buffer) {
    return new Promise((resolve) => {
        const worker = new Worker("wave-worker.js"); // A worker to process the WAV file
        worker.postMessage(buffer);

        worker.onmessage = (e) => {
            const { data } = e;
            resolve(new Blob([data], { type: "audio/wav" }));
        };
    });
}

// Start recording
startButton.addEventListener("click", async () => {
    try {
        audioChunks = [];
        secondsElapsed = 0;

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.start();

        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunks.push(event.data);
            }
        };

        mediaRecorder.addEventListener("stop", async () => {
            audioBlob = new Blob(audioChunks, { type: "audio/wav" });

            // If trimming is required
            if (startTrim >= 0 && endTrim > startTrim) {
                const trimmedAudio = await trimAudio(audioBlob, startTrim, endTrim);

                // Send the trimmed audio to the server
                uploadAudio(trimmedAudio);
            } else {
                // Send the full audio to the server
                uploadAudio(audioBlob);
            }

            // Display the recorded or trimmed audio preview
            const audioUrl = URL.createObjectURL(audioBlob);
            audioPreview.src = audioUrl;
            audioPreview.style.display = "block";
        });

        // UI updates
        recordingAlert.style.display = "block";
        recordingTime.textContent = secondsElapsed + " seconds";
        startRecordingTimer();
        startButton.disabled = true;
        stopButton.disabled = false;
    } catch (err) {
        console.error("Error starting audio recording:", err);
        alert("Failed to start audio recording. Please try again.");
    }
});

// Stop recording
stopButton.addEventListener("click", () => {
    if (mediaRecorder) {
        mediaRecorder.stop();
        stopRecordingTimer();
        recordingAlert.style.display = "none";
        startButton.disabled = false;
        stopButton.disabled = true;
    }
});

// Upload audio
function uploadAudio(blob) {
    const formData = new FormData();
    formData.append("recorded_audio", blob, "trimmed_audio.wav");

    fetch("{{ url_for('upload_media') }}", {
        method: "POST",
        body: formData,
    })
        .then((response) => {
            if (response.ok) {
                alert("Audio successfully uploaded!");
            } else {
                alert("Error uploading audio. Please try again.");
            }
        })
        .catch((err) => {
            console.error("Upload error:", err);
            alert("Error uploading audio. Please try again.");
        });
}

</script>

{% endblock %}
